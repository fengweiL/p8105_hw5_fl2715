---
title: "p8105_hw5_fl2715"
author: "Fengwei Lei"
output: github_document
---

## Loading Library and Setting Seed
```{r, message = FALSE, warning = FALSE}
library(tidyverse)

set.seed(1)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1
Firstly, we define a function.
```{r}
birthday_sim=function(n){
  birthdays=sample(1:365, size=n, replace=TRUE)
  duplicate=length(birthdays)!= length((unique(birthdays)))
  return(duplicate)
}
```

And then, we run this function 10000 times for each group size between 2 and 50. And we create a tibble for the result. 
```{r}
num_simulations = 10000
group_sizes = 2:50
probabilities = numeric(length(group_sizes))

for (i in seq_along(group_sizes)) {
  n = group_sizes[i]
  duplicate_count = sum(replicate(num_simulations, birthday_sim(n)))
  probabilities[i] = duplicate_count / num_simulations
}

result=tibble(group_sizes, probabilities)
```

Next, we make a plot showing the probability Vs the different group sizes.
```{r}
ggplot(aes(x=group_sizes, y=probabilities), data=result) +
  geom_line()
```

**Comment**: 
From the above the plot, we can see that the probability that at least two people share a birthday increases as the group size increases. When the group size is 50, the probability of sharing birthday is about 0.97, which is close to 1.

## Problem 2

We first contruct the function of the required normal model.
```{r}
sim_norm=function(mu){
  n=30
  sigma=5
  sim_data=tibble(
    x=rnorm(n, mean=mu, sd=sigma)
  )
  
  mu_hat=sim_data$x
  p_value=t.test(sim_data$x, mu = 0) |> 
    broom::tidy() |> 
    pull(p.value)
  
  tibble(mu_hat=mu_hat, p_value=p_value)
}
```

Then, we generate 5000 datasets for the model.
```{r}
sim_results_df = 
  expand_grid(
    mu =0:6,
    iter = 1:5000
  ) |> 
  mutate(
    estimate_df = map(mu, sim_norm)
  ) |> 
  unnest(estimate_df)
  
```

Next, we make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of $\mu$ on the x axis.
```{r}
alpha=0.05
power_data = sim_results_df |> 
  group_by(mu)  |> 
  summarize(
    power = mean(p_value < alpha)
  )

# Plot the power as a function of the true mean (mu)
power_data |> 
  ggplot(aes(x = mu, y = power)) +
    geom_line(color = "blue") +
    geom_point(color = "blue") +
    labs(
      title = "Power of the Test vs. True Mean",
      x = "True Mean (mu)",
      y = "Power (Probability of Rejecting Null)"
    )
```

Describe the association between **effect size and power**:
From the above plot, we can see that the power of the test increases as the true mean increases from zero. It indicates a positive association between effect size and power.


Finally, we make a plot for showing the average estimate of ($\hat{\mu}$) across each true mean for all sample cases and the null rejected cases.
```{r}
mu_estimates = sim_results_df  |> 
  group_by(mu)  |> 
  summarize(
    avg_mu_hat = mean(mu_hat),
    avg_mu_hat_rejected = mean(mu_hat[p_value < alpha])
  )

mu_estimates |> 
  ggplot(aes(x = mu)) +
    geom_line(aes(y = avg_mu_hat, color = "All samples")) +
    geom_line(aes(y = avg_mu_hat_rejected, color = "Rejected samples")) +
    geom_point(aes(y = avg_mu_hat, color = "All samples")) +
    geom_point(aes(y = avg_mu_hat_rejected, color = "Rejected samples")) +
    labs(
      title = "Average Estimate of mu_hat",
      x = "True Mean (mu)",
      y = "Average Estimate of mu_hat"
    ) +
    scale_color_manual(values = c("blue", "red"),
                       name = "Sample Type",
                       labels = c("All samples", "Rejected samples"))
```

For the samples where the null was rejected, the average estimate of ($\hat{\mu}$) tends to be slightly higher than the true value when true mean is 0, 1, 2, and 3. The average estimate of ($\hat{\mu}$) is equal to the true mean when true mean is 4, 5, and 6. This is due to selection bias: tests are more likely to reject when sample means are further from zero, creating an upward bias in the average estimate when conditioning on rejection.

## Problem 3

First, we load the raw dataset. This dataset contains information on homicides in 50 large U.S. cities. It includes 52179 observations and 12 variables. For each homicide observation, the data include details such as the report date, location, victim characteristics, and case status.
```{r}
homicide_data_raw = read_csv("data/homicide-data.csv") |>
  janitor::clean_names()

head(homicide_data_raw)
```

Then, we create the `city_state` variable. And we summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).
```{r}
homicide_data =homicide_data_raw |> 
  mutate(
    city_state = paste(city, state, sep = ", "),
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  )  

homicide_city = homicide_data |> 
  group_by(city)  |> 
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved)
  )

knitr::kable(homicide_city)
```

Next, for Baltimore, MD, we’ll use the `prop.test` function to estimate the proportion of unsolved homicides. We will tidy the results with `broom::tidy` to extract the estimated proportion and confidence intervals.
```{r}
baltimore_summary = homicide_data |> 
  filter(city_state == "Baltimore, MD") |> 
  summarize(
    unsolved_homicides = sum(unsolved),
    total_homicides = n()
  ) 

baltimore_test= prop.test(
  baltimore_summary$unsolved_homicides,
  baltimore_summary$total_homicides
)

baltimore_results = broom::tidy(baltimore_test)  |> 
  select(estimate, conf.low, conf.high)

knitr::kable(baltimore_results, caption="Proportion Test Results for Baltimore, MD")
```

Next, we will perform a `prop.test` for each city to estimate the proportion of unsolved homicides and extract confidence intervals. We’ll use a tidy pipeline with `purrr::map2` to apply `prop.test` across all cities.
```{r}
city_test_results = homicide_city |> 
  mutate(
    test_results =  map2(unsolved_homicides, total_homicides, \(x, y) broom::tidy(prop.test(x, y)))
  )  |> 
  unnest(test_results)  |> 
  select(city, estimate, conf.low, conf.high)

knitr::kable(city_test_results, caption="Proportion Test Results across Each City")
```

Finally, we will create a plot that shows the estimated proportion of unsolved homicides for each city, along with their confidence intervals.
```{r}
city_test_results = city_test_results  |> 
  arrange(desc(estimate))  |> 
  mutate(city = factor(city, levels = city))

city_test_results |> 
ggplot(aes(x = city, y = estimate)) +
  geom_point(color = "red") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.25) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Proportion of Unsolved Homicides (with 95% CI)"
  )
```


